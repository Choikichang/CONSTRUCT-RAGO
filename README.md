<div align="center">

# CONSTRUCT-RAG ğŸ—ï¸

**Contrastive Sentence Training & Retrieval Using Chunk block-based Text for RAG**

[![Paper](https://img.shields.io/badge/Paper-SSRN-blue)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5205959)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![arXiv](https://img.shields.io/badge/arXiv-2025.XXXXX-b31b1b.svg)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5205959)
![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/KichChat/CONSTRUCT-RAG/graphs/commit-activity)

</div>

<p align="center">
  <img src="https://raw.githubusercontent.com/KichChat/CONSTRUCT-RAG/main/figures/construct-rag-overview.png" alt="CONSTRUCT-RAG Overview" width="750px">
</p>

## ğŸ“‹ ëª©ì°¨ / Table of Contents

- [ì†Œê°œ (í•œêµ­ì–´)](#-ì†Œê°œ-í•œêµ­ì–´)
- [Introduction (English)](#-introduction-english)
- [ì£¼ìš” ê¸°ëŠ¥ / Key Features](#-ì£¼ìš”-ê¸°ëŠ¥--key-features)
- [ì„¤ì¹˜ ë°©ë²• / Installation](#-ì„¤ì¹˜-ë°©ë²•--installation)
- [ì‚¬ìš© ë°©ë²• / Usage](#-ì‚¬ìš©-ë°©ë²•--usage) 
- [ì¸ìš© / Citation](#-ì¸ìš©--citation)
- [ë¼ì´ì„¼ìŠ¤ / License](#-ë¼ì´ì„¼ìŠ¤--license)
- [ì—°ë½ì²˜ / Contact](#-ì—°ë½ì²˜--contact)

## ğŸŒŸ ì†Œê°œ (í•œêµ­ì–´)

CONSTRUCT-RAGëŠ” í•œêµ­ì–´ì™€ ê°™ì€ ì €ìì› ì–¸ì–´ì—ì„œ ê±´ì„¤ ë¶„ì•¼ ë¬¸ì„œë¥¼ ìœ„í•œ ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG) ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” í˜ì‹ ì ì¸ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì¶”ë¡  ëŠ¥ë ¥ì´ ë›°ì–´ë‚˜ì§€ë§Œ í•œêµ­ì–´ì™€ ê°™ì€ ì €ìì› ì–¸ì–´, íŠ¹íˆ ê±´ì„¤ ë¶„ì•¼ì—ì„œëŠ” í• ë£¨ì‹œë„¤ì´ì…˜ ë¬¸ì œì™€ ì •í™•ë„ í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.

ì´ ì—°êµ¬ëŠ” ëŒ€ì¡°ì  ë¬¸ì¥ ìƒì„±(CSG)ê³¼ ë¬¸ì¥ ë¸”ë¡ ì„ë² ë”©(SBE)ì„ í†µí•©í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ì™€ ì‘ë‹µ ìƒì„±ì„ í¬ê²Œ ê°œì„ í–ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ ë°©ì‹ì€ 10ë‹¬ëŸ¬ ë¯¸ë§Œì˜ ë¹„ìš©ìœ¼ë¡œ ê³ í’ˆì§ˆ ì„ë² ë”© ëª¨ë¸ì„ êµ¬ì¶•í•˜ì—¬, OpenAIì˜ text-embedding-3-largeë³´ë‹¤ 17% í–¥ìƒëœ ê²€ìƒ‰ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

### ì„±ê³¼
- **ê²€ìƒ‰ ì •í™•ë„**: Top-1 ê²€ìƒ‰ ì •í™•ë„ 69.32% ë‹¬ì„±
- **ì‘ë‹µ ì •í™•ë„**: BERTScore 94.51%, LLM-as-a-Judge í‰ê°€ì—ì„œ 61.99% ì •í™•ë„ ë‹¬ì„±
- **ê²½ëŸ‰í™”ëœ ëª¨ë¸**: 443MB í¬ê¸°ì˜ ëª¨ë¸ë¡œ ì €ìì› í™˜ê²½ì—ì„œë„ íš¨ìœ¨ì  ì‹¤í–‰

### ë°ì´í„°ì…‹
- **KorConNLI**: í•œêµ­ì–´ ê±´ì„¤ í‘œì¤€ ì‹œë°©ì„œì—ì„œ ì¶”ì¶œí•œ 5,666ê°œ ë¬¸ì¥ ìŒìœ¼ë¡œ êµ¬ì„±ëœ í•™ìŠµ ë°ì´í„°ì…‹
- **í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹**: í•œêµ­ í† ì§€ì£¼íƒê³µì‚¬(LH) ê±´ì„¤ ì‹œë°©ì„œì—ì„œ ìƒì„±í•œ 1,255ê°œ ì§ˆë¬¸-ë‹µë³€ ìŒ

## ğŸŒ Introduction (English)

CONSTRUCT-RAG is an innovative framework designed to enhance Retrieval-Augmented Generation (RAG) performance for construction domain documents in low-resource languages like Korean. While Large Language Models (LLMs) demonstrate excellent reasoning capabilities, they suffer from hallucination issues and accuracy limitations in low-resource languages, particularly in specialized domains like construction.

Our research integrates Contrastive Sentence Generation (CSG) and Sentence Block Embedding (SBE) to significantly improve retrieval accuracy and response generation. Our approach builds high-quality embedding models for less than $10, achieving retrieval performance that outperforms OpenAI's text-embedding-3-large by 17%.

### Achievements
- **Retrieval Accuracy**: Achieved 69.32% top-1 retrieval accuracy
- **Answer Accuracy**: Achieved 94.51% BERTScore and 61.99% accuracy in LLM-as-a-Judge evaluation
- **Lightweight Model**: 443MB model size enables efficient execution in resource-constrained environments

### Datasets
- **KorConNLI**: Training dataset consisting of 5,666 sentence pairs extracted from Korean Construction Standard Specifications
- **Test Dataset**: 1,255 question-answer pairs generated from Land and Housing Corporation (LH) construction specifications

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥ / Key Features

<div align="center">
<table>
  <tr>
    <td align="center"><img src="https://raw.githubusercontent.com/KichChat/CONSTRUCT-RAG/main/figures/csg.png" width="250px"><br><b>CSG</b><br>Contrastive Sentence Generation</td>
    <td align="center"><img src="https://raw.githubusercontent.com/KichChat/CONSTRUCT-RAG/main/figures/sbe.png" width="250px"><br><b>SBE</b><br>Sentence Block Embedding</td>
    <td align="center"><img src="https://raw.githubusercontent.com/KichChat/CONSTRUCT-RAG/main/figures/mrl.png" width="250px"><br><b>MRL</b><br>Matryoshka Representation Learning</td>
  </tr>
</table>
</div>

- **ëŒ€ì¡°ì  ë¬¸ì¥ ìƒì„± (CSG)**: LLMì„ í™œìš©í•˜ì—¬ ê²½ì œì ìœ¼ë¡œ ëŒ€ì¡°ì  ë¬¸ì¥ ìŒì„ ìƒì„±
- **ë¬¸ì¥ ë¸”ë¡ ì„ë² ë”© (SBE)**: ê¸´ ë¬¸ì„œì˜ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” í˜ì‹ ì ì¸ ì„ë² ë”© ë°©ë²•
- **Matryoshka í‘œí˜„ í•™ìŠµ**: ë‹¤ì¤‘ ë²¡í„° ì°¨ì›ì„ í†µí•œ íš¨ìœ¨ì ì¸ ì„ë² ë”© ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •
- **ë‹¤ì¤‘ ë¶€ì • ë­í‚¹ ì†ì‹¤ (MNRL)**: ì˜ë¯¸ë¡ ì  ê´€ê³„ì„±ì— ê¸°ë°˜í•œ ê³ ê¸‰ ì„ë² ë”© í•™ìŠµ ë°©ë²•

## ğŸ’» ì„¤ì¹˜ ë°©ë²• / Installation

```bash
# ì €ì¥ì†Œ ë³µì œ
git clone https://github.com/KichChat/CONSTRUCT-RAG.git
cd CONSTRUCT-RAG

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# (ì„ íƒì‚¬í•­) ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
python download_models.py
```

## ğŸ“Š ì‚¬ìš© ë°©ë²• / Usage

### ë°ì´í„°ì…‹ ìƒì„± / Dataset Generation

```python
from construct_rag import CSGGenerator

# ëŒ€ì¡°ì  ë¬¸ì¥ ìƒì„± (CSG)
generator = CSGGenerator(model="gpt-4o")
dataset = generator.generate_from_documents("path/to/construction/docs", num_pairs=100)
dataset.save("construction_dataset.jsonl")
```

### ì„ë² ë”© ëª¨ë¸ ë¯¸ì„¸ ì¡°ì • / Fine-tuning Embedding Model

```python
from construct_rag import EmbeddingTrainer

# ëª¨ë¸ ë¯¸ì„¸ ì¡°ì •
trainer = EmbeddingTrainer(base_model="KLUE-RoBERTa-base")
trainer.train(
    dataset_path="construction_dataset.jsonl",
    output_dir="fine-tuned-model",
    use_mnrl=True,
    use_mrl=True
)
```

### RAG ì‹œìŠ¤í…œ ì‚¬ìš© / Using the RAG System

```python
from construct_rag import ConstructRAG

# CONSTRUCT-RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
rag = ConstructRAG(
    embedding_model="fine-tuned-model",
    llm_model="gpt-4o",
    use_sbe=True
)

# ë¬¸ì„œ ì¸ë±ì‹±
rag.index_documents("path/to/construction/docs")

# ì§ˆì˜ì‘ë‹µ
answer = rag.query("ì½˜í¬ë¦¬íŠ¸ ë²½ì²´ ì‹œê³µ ì‹œ ë‘ê»˜ëŠ” ì–¼ë§ˆë¡œ í•´ì•¼ í•˜ë‚˜ìš”?")
print(answer)
```

## ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ / Performance Comparison

<p align="center">
  <img src="https://raw.githubusercontent.com/KichChat/CONSTRUCT-RAG/main/figures/performance.png" alt="Performance Comparison" width="700px">
</p>

ëª¨ë¸ ë¹„êµ / Model Comparison:

| ëª¨ë¸ | Hit Rate@1 | NDCG@5 | MRR@5 | ëª¨ë¸ í¬ê¸° |
|------|------------|--------|-------|----------|
| KLUE-RoBERTa-base | 12.40% | 0.1983 | 0.1766 | 443MB |
| KLUE-RoBERTa-base + MNRL | 58.65% | 0.6904 | 0.6621 | 443MB |
| KLUE-RoBERTa-base + MNRL + MRL | 59.60% | 0.7454 | 0.7047 | 443MB |
| KLUE-RoBERTa-base + MNRL + MRL + SBE | **69.32%** | **0.8082** | **0.7769** | 443MB |
| multilingual-e5-large | 59.84% | 0.7336 | 0.6961 | 2.24GB |
| text-embedding-3-large | 52.67% | 0.6784 | 0.6349 | - |

## ğŸ“š ì¸ìš© / Citation

ë…¼ë¬¸ì„ ì¸ìš©í•˜ë ¤ë©´ ë‹¤ìŒ BibTeX í•­ëª©ì„ ì‚¬ìš©í•˜ì„¸ìš”:

```bibtex
@article{choi2025constructrag,
  title={CONSTRUCT-RAG: Contrastive Sentence Training \& Retrieval Using Chunk block-based Text for RAG},
  author={Choi, Kichang and Jeong, Minwoo and Shin, Younga and Ma, Jongwon and Kim, Kinam and Kim, Hongjo},
  journal={Automation in Construction},
  year={2025},
  publisher={Elsevier},
  note={Preprint}
}
```

## ğŸ“„ ë¼ì´ì„¼ìŠ¤ / License

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„¼ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“¬ ì—°ë½ì²˜ / Contact

- **êµì‹ ì €ì**: ê¹€í™ì¡° (hongjo@yonsei.ac.kr)
- **ê¸°ê´€**: ì—°ì„¸ëŒ€í•™êµ í† ëª©í™˜ê²½ê³µí•™ê³¼, ì„œìš¸ì‹œ ì„œëŒ€ë¬¸êµ¬ ì—°ì„¸ë¡œ 50, 03722, ëŒ€í•œë¯¼êµ­
- **GitHub Issues**: ë¬¸ì œë‚˜ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ [GitHub Issues](https://github.com/KichChat/CONSTRUCT-RAG/issues)ì— ë“±ë¡í•´ì£¼ì„¸ìš”.

---

<div align="center">
  <sub>Built with â¤ï¸ by Kichang Choi, Minwoo Jeong, Younga Shin, Jongwon Ma, Kinam Kim, and Hongjo Kim.</sub>
</div>


# RAG-Construction
ì ê²Œ ì‚¬ìš©ë˜ëŠ” ì†Œìˆ˜ì–¸ì–´(korean)ì—ì„œ íŠ¹ì •í•œ domainì— ê¹Œì§€ ì ìš©í•˜ê²Œë˜ë©´ RAG ì„±ëŠ¥ì´ ì•½í™”ëœë‹¤.
ì œëŒ€ë¡œ ì„±ëŠ¥ ë°œíœ˜ê°€ ì•ˆë˜ëŠ” í˜„ìƒì´ ë§ì´ ë°œìƒí•¨.
ì„ë² ë”© ëª¨ë¸ì´ RAG ì„±ëŠ¥ì— ë¬´ì‹œí•  ìˆ˜ ì—†ëŠ” ì˜í–¥ì„ ë¯¸ì¹ ê±°ë¼ê³  ìƒê°í•˜ê³ 
ì„ë² ë”© ëª¨ë¸ì´ RAG ì„±ëŠ¥ì— ë¼ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•œ ì—°êµ¬ê°€ ë‚´ê°€ ì—°êµ¬í•˜ëŠ” í•œì—ì„œëŠ” ì—†ë‹¤ê³  íŒë‹¨í•˜ì—¬ ì—°êµ¬ë¥¼ ì§„í–‰í•˜ê²Œ ë˜ì—ˆë‹¤.


## 1. ì˜¤í”ˆ ì†ŒìŠ¤ ê¸°ë°˜ Local RAG í˜•ì„±
    Embedding ëª¨ë¸ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ê°€ ìˆì„ê²ƒì´ë¼ê³  íŒë‹¨
    ko-roberta, GPT4ALL, openai-embedding ì„¸ê°€ì§€ ë¹„êµ
    í•œêµ­ì–´ ì—ì„œëŠ” ko-robertaê°€ ê°€ì¥ ìš°ìˆ˜í–ˆë‹¤.
    ê±´ì„¤ ë„ë©”ì¸ì— ë§ëŠ” ì„ë² ë”© ëª¨ë¸ ìƒì„±ì´ ëª©í‘œ

## 2. ì„ë² ë”© ëª¨ë¸ íŒŒì¸ íŠœë‹ Dataset ìƒì„±
    KDS(korean design standard) ë¥¼ ì‚¬ìš©
    hwpíŒŒì¼ì„ txt íŒŒì¼ë¡œ ë³€í™˜ (í‘œì™€ ê·¸ë¦¼ì€ ëª»ì½ì–´ì˜´, ì¤‘ê°„ì— ëª»ë¶ˆëŸ¬ì˜¨ ë°ì´í„° ì¡´ì¬)

    txt ë°ì´í„°ë¥¼ ë¬¸ì¥ ë³€í™˜
    STS ë°ì´í„°ì…‹
        ë¬¸ì„œ ë‚´ ìš©ì–´ ì •ì˜ íŒŒíŠ¸ì—ì„œ ê°€ì§€ê³ ì˜´
        ìš©ì–´ : ì„¤ëª… í˜•íƒœë¡œ êµ¬ì„±ë˜ì–´ìˆìŒ
        ì´ë•Œ ìš©ì–´ì™€ ì„¤ëª…ì€ ë™ì¼í•˜ë‹¤ê³  ê°€ì •í•˜ì˜€ë‹¤.
    ìš©ì–´ : ì„¤ëª… í˜•íƒœì˜ ìœ ì‚¬ë„ 5ì¸ 559ê°œì˜ ë°ì´í„°ì…‹ ìƒì„±

    NLI ë°ì´í„°ì…‹
        1. kiwi ë¬¸ì¥ ì¶”ì¶œ
        2. ì‹œì‘ì´ ìˆœì„œìˆëŠ” ê¸€ë¨¸ë¦¬ or íŠ¹ìˆ˜ë¬¸ì or ì ‘ì†ì‚¬ ì¸ê²½ìš° ë¬¸ì¥ ì œì™¸
        3. íŠ¹ìˆ˜ ë¬¸ì 2ê°œ ì´ìƒ í¬í•¨ë˜ì–´ìˆëŠ” ë¬¸ì¥ ì œì™¸
        4. ëì—ì„œ 2ê¸€ì ì´ë‚´ ì¢…ê²°ì–´ë¯¸ê°€ ì˜¤ì§€ ì•ŠëŠ” ë¬¸ì¥ ì œì™¸
        5. ì¼ë°˜ëª…ì‚¬ 5ê°œ ì´ìƒ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì€ ë¬¸ì¥ ì œì™¸
    ê²°ê³¼ 16,450ê°œì˜ ë¹„êµì  ì–‘ì§ˆì˜ ë°ì´í„° í™•ë³´
    ê° ë¬¸ì¥ì„ EEVE í•œêµ­ì–´ LLMì— ì…ë ¥í•˜ê³  í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì‘í•˜ì—¬ ê° ë¬¸ì¥ë§ˆë‹¤ Neural, Contradiction, Entailment
    ì„¸ê°€ì§€ í˜•íƒœì˜ ë¬¸ì¥ ìƒì„±í•˜ë„ë¡ í•˜ê³  ìƒì„±ëœ ë¬¸ì¥ì˜ ì¢…ë¥˜ë¥¼ gold_labelì— ì €ì¥
    gold ë¼ë²¨ì— ë‹¤ì–‘í•œ ë§ì´ ë“¤ì–´ê°”ìŒ ì •ë¦¬ í•„ìš”

## 3. ì„ë² ë”© ëª¨ë¸ íŒŒì¸íŠœë‹
    nli ë°ì´í„°ì…‹, sts ë°ì´í„°ì…‹, multi ì„¸ê°€ì§€ ì¢…ë¥˜ë¡œ íŠ¸ë ˆì´ë‹ ì‹œí‚¨ë‹¤.
    klue/roberta, jhgan00/ko-sentence-transformer ë‘ê°œë¥¼ ê°ê° íŠ¸ë ˆì´ë‹ ì‹œì¼œë³¸ë‹¤.
    ì´ 6ê°€ì§€ modelì´ ë‚˜ì˜¤ê²Œë¨ ë¨¼ì € ê°„ë‹¨í•˜ê²Œ 3ê°€ì§€ ë¬¸ì¥ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•´ë³¸ë‹¤.

    loss function

## 4. ê±´ì„¤ ë„ë©”ì¸ RAG Test ë°ì´í„°ì…‹ ìƒì„±
    ê±´ì„¤ ì–´ë–¤ ë¬¸ì„œë¥¼ ê°€ì§€ê³ ì™€ì„œ LLMì„ í†µí•´ summaryí•˜ê³  ê·¸ì— ëŒ€í•œ ì§ˆë¬¸ê³¼ ë‹µë³€ pairë¥¼ ìƒì„±
    ê°ê° numbering í•˜ê³  test datasetì„ ìƒì„±
    ë¬¸ì„œë¥¼ ê°€ì§€ê³  ì˜¬ë•Œ
    ê¸°ì¤€ ë¬¸ì„œì— ì—†ëŠ” êµ¬ì¡° ê¸°ì¤€ê°€ì§€ê³  ë§Œë“¤ì–´ë³´ê¸°, í•´ìˆ˜ë¶€ë‚˜ ë‹¤ë¥¸ ê¸°ê´€ êµ¬ì¡°ê²€í† ìª½ìœ¼ë¡œ í•´ì„œ
    KICT Q&A ë°ì´í„°ì…‹ í™œìš©ë„ í•´ë³´ê³ 
    ê·¸ë¦¬ê³  GPT4 ê°™ì€ê²ƒê³¼ í•œë²ˆ ë¹„êµë„ í•´ë³´ê¸°

## 5. Retriever ì„±ëŠ¥ í…ŒìŠ¤íŠ¸


### ê°œì„ ì˜ˆìƒë˜ëŠ” ì§€ì 
1. Test Dataset ìƒì„±ì‹œ KICT Q&A ë°ì´í„° ì‚¬ìš©
2. Test Dataset ìƒì„±ì‹œ í•˜ì ë°ì´í„° ì‚¬ìš©
3. fck ê°™ì€ ì•½ì–´ ì¸ì‹í•˜ë„ë¡ ë³€ê²½
4. ì¸ì‹ë˜ì§€ ì•Šê³ ìˆëŠ” hwp íŒŒì¼ë“¤ ì¸ì‹ì‹œí‚¤ê¸°
4. QA instruction data ìƒì„±í•´ì„œ LLM íŒŒì¸íŠœë‹ë„ ê°€ëŠ¥í•  ë“¯
5. loss function ê°œì„ 
6. LLM íŒŒì¸íŠœë‹
7. Embedidng modelì— ì‚¬ìš©ëœ Tokenizerë¥¼ íŠœë‹, í˜„ì¬ Tokenizerì—ëŠ” ê±´ì„¤ì— ê´€ë ¨ëœ ë‹¨ì–´ê°€ ì—†ë‹¤.
8. SBERT ë‹¨ì–´ì¥ Word piece ì— ê±´ì„¤ domain 551 ê°€ì§€ ë‹¨ì–´ë¥¼ ì¶”ê°€í•˜ê¸°

í•„ìš”í•œê²ƒ
1. SBERT, RoBERTa ë…¼ë¬¸ë¦¬ë·°
2. MultipleNegativeRankLoss
